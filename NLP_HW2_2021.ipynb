{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP HW2 (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дарья Родионова БКЛ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation extraction + NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import *\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачивание и подготовка корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d692e8ba6646a7b629f1962df97041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('Musical_Instruments_5.json', 'r') as f:\n",
    "    for l in tqdm(f):\n",
    "        data.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 5.0,\n",
       " 'verified': True,\n",
       " 'reviewTime': '10 30, 2016',\n",
       " 'reviewerID': 'A3FO5AKVTFRCRJ',\n",
       " 'asin': '0739079891',\n",
       " 'reviewerName': 'francisco',\n",
       " 'reviewText': \"It's good for beginners\",\n",
       " 'summary': 'Five Stars',\n",
       " 'unixReviewTime': 1477785600}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 30, 2016</td>\n",
       "      <td>A3FO5AKVTFRCRJ</td>\n",
       "      <td>0739079891</td>\n",
       "      <td>francisco</td>\n",
       "      <td>It's good for beginners</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1477785600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 30, 2016</td>\n",
       "      <td>A3UCGC1DHFMBCE</td>\n",
       "      <td>0739079891</td>\n",
       "      <td>Eb Jack Murray</td>\n",
       "      <td>I recommend this starter Ukulele kit.  I has e...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1467244800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 9, 2016</td>\n",
       "      <td>A2S9SLRYLPGYZB</td>\n",
       "      <td>0739079891</td>\n",
       "      <td>Clara LaMarr</td>\n",
       "      <td>G'daughter received this for Christmas present...</td>\n",
       "      <td>Learning new songs to play regularly</td>\n",
       "      <td>1462752000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 10, 2016</td>\n",
       "      <td>A15RTJWPG8OKOE</td>\n",
       "      <td>0739079891</td>\n",
       "      <td>Eagle80</td>\n",
       "      <td>According to my order history, I bought this t...</td>\n",
       "      <td>A bargain-bin good-enough ukulele that's held ...</td>\n",
       "      <td>1460246400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 6, 2016</td>\n",
       "      <td>A12ET1WO3OAVU7</td>\n",
       "      <td>0739079891</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Please pay attention better than I did to the ...</td>\n",
       "      <td>Poor Quality product.</td>\n",
       "      <td>1454716800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True  10 30, 2016  A3FO5AKVTFRCRJ  0739079891   \n",
       "1      5.0      True  06 30, 2016  A3UCGC1DHFMBCE  0739079891   \n",
       "2      5.0      True   05 9, 2016  A2S9SLRYLPGYZB  0739079891   \n",
       "3      4.0      True  04 10, 2016  A15RTJWPG8OKOE  0739079891   \n",
       "4      1.0      True   02 6, 2016  A12ET1WO3OAVU7  0739079891   \n",
       "\n",
       "      reviewerName                                         reviewText  \\\n",
       "0        francisco                            It's good for beginners   \n",
       "1   Eb Jack Murray  I recommend this starter Ukulele kit.  I has e...   \n",
       "2     Clara LaMarr  G'daughter received this for Christmas present...   \n",
       "3          Eagle80  According to my order history, I bought this t...   \n",
       "4  Amazon Customer  Please pay attention better than I did to the ...   \n",
       "\n",
       "                                             summary  unixReviewTime vote  \\\n",
       "0                                         Five Stars      1477785600  NaN   \n",
       "1                                         Five Stars      1467244800  NaN   \n",
       "2               Learning new songs to play regularly      1462752000  NaN   \n",
       "3  A bargain-bin good-enough ukulele that's held ...      1460246400  NaN   \n",
       "4                              Poor Quality product.      1454716800  NaN   \n",
       "\n",
       "  style image  \n",
       "0   NaN   NaN  \n",
       "1   NaN   NaN  \n",
       "2   NaN   NaN  \n",
       "3   NaN   NaN  \n",
       "4   NaN   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'asin': 'instrumentID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Предложите 3 способа найти упоминания товаров в отзывах. Например, использовать bootstrapping: составить шаблоны вида \"холодильник XXX\", найти все соответствующие n-граммы и выделить из них называние товара. Могут помочь заголовки и дополнительные данные с Amazon (Metadata здесь) Какие данные необходимы для каждого из способов? Какие есть достоинства/недостатки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скачать метаданные и выделить оттуда сущестивиетльные из title каждого товара. Достоинствами метода являются простота и скорость. Однако этот метод, скорее всего, будет лучше работать на длинных отзывах, потому что с ними выше вероятность, что автор назовёт товар именно нужным нам словом из названия. В целом получается достаточно низкий recall. Можно улучшить этот метод, добавив к названиям общие слова типа product, item и (в нашем случае) instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Посчитать самые частотные существительные и свести их с гиперонимами из WordNet. Главное достоинство — всё находится автоматически. Но не для всех слов можно найти синонимы/гиперонимы, также не решается проблема с сокращениями и другими названиями товара."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Использование готовых нейросетей. Так мы сможем найти сложные зависимости, но есть риск потерять важные коллокации, потому что будут выделяться только названия брендов, а общие названия продуктов — нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Реализуйте один из предложенных вами способов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила реализовать второй способ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "for i, d in enumerate(data):\n",
    "    try:\n",
    "        _ = d['reviewText']\n",
    "    except KeyError:\n",
    "        empty.append(i)\n",
    "        \n",
    "# print(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [d['reviewText'] for i, d in enumerate(data) if i not in empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac89a28d0571422995fc90deefa423a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=231344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_corpus = []\n",
    "\n",
    "for text in tqdm(corpus):\n",
    "    processed_corpus.append(nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9cca43a7a844eda44cba9e9f53989e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=231344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15629086"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = []\n",
    "\n",
    "for doc in tqdm(processed_corpus):\n",
    "    for token in doc:\n",
    "        lemmas.append((token.lemma_, token.pos_))\n",
    "        \n",
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахожу самые частотные слова в целом и отдельно смотрю на существительные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4784"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(lemmas)\n",
    "\n",
    "top_words_tagged = []\n",
    "top_nouns_tagged = []\n",
    "\n",
    "for w_t, f in freq.most_common(5000):\n",
    "    w, t = w_t\n",
    "    if w not in stops and w not in string.punctuation:\n",
    "        top_words_tagged.append(w)\n",
    "        if t == 'NOUN':\n",
    "            top_nouns_tagged.append(w)\n",
    "\n",
    "len(top_words_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guitar',\n",
       " 'string',\n",
       " 'sound',\n",
       " 'price',\n",
       " 'pedal',\n",
       " 'quality',\n",
       " 'time',\n",
       " 'one',\n",
       " 'product',\n",
       " 'amp',\n",
       " 'cable',\n",
       " 'tone',\n",
       " 'thing',\n",
       " 'year',\n",
       " 'case',\n",
       " 'pick',\n",
       " 'stand',\n",
       " 'bass',\n",
       " 'lot',\n",
       " 'way',\n",
       " 'instrument',\n",
       " 'bit',\n",
       " 'strap',\n",
       " 'mic',\n",
       " 'tuner',\n",
       " 'problem',\n",
       " 'set',\n",
       " 'power',\n",
       " 'review',\n",
       " 'effect',\n",
       " 'music',\n",
       " 'unit',\n",
       " 'end',\n",
       " 'speaker',\n",
       " 'money',\n",
       " 'volume',\n",
       " 'neck',\n",
       " 'issue',\n",
       " 'bag',\n",
       " 'box',\n",
       " 'work',\n",
       " 'use',\n",
       " 'size',\n",
       " 'star',\n",
       " 'microphone',\n",
       " 'light',\n",
       " 'drum',\n",
       " 'job',\n",
       " 'noise',\n",
       " 'pickup']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nouns_tagged[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаю нужные слова из поддерева _musical_instrument.n.01_ в WordNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barrel_organ.n.01', 'bass.n.07', 'calliope.n.02', 'electronic_instrument.n.01', \"jew's_harp.n.01\", 'keyboard_instrument.n.01', 'music_box.n.01', 'percussion_instrument.n.01', 'stringed_instrument.n.01', 'wind_instrument.n.01']\n"
     ]
    }
   ],
   "source": [
    "base = wn.synset('musical_instrument.n.01')\n",
    "all_names = [s.name() for s in base.hyponyms()]\n",
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musical_instruments = []\n",
    "syns = [base]\n",
    "\n",
    "while syns:\n",
    "    for syn in syns:\n",
    "        musical_instruments.append(syn)\n",
    "        syns.remove(syn)\n",
    "        syns.extend(syn.hyponyms())\n",
    "\n",
    "instruments_list = list(set(musical_instruments))\n",
    "len(instruments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_musical_instruments = []\n",
    "for i in instruments_list:\n",
    "    all_musical_instruments.extend(i.lemma_names()) \n",
    "\n",
    "len(all_musical_instruments)\n",
    "# print(all_musical_instruments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставляем только те частотные существительные, которые есть в WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recorder', 'chime', 'dulcimer', 'wood', 'grand', 'bongo', 'snare', 'guitar', 'cello', 'piano', 'banjo', 'saxophone', 'wind', 'baritone', 'uke', 'sax', 'tambourine', 'trombone', 'reed', 'drum', 'fiddle', 'violin', 'ukulele', 'triangle', 'organ', 'string', 'bell', 'mandolin', 'whistle', 'pipe', 'instrument', 'harp', 'horn', 'trumpet', 'harmonica', 'clarinet', 'cymbal', 'flute', 'synthesizer', 'bass', 'brass', 'upright']\n"
     ]
    }
   ],
   "source": [
    "instruments = list(set([i for i in top_words_tagged if i in all_musical_instruments]))\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instruments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Соберите n-граммы с полученными сущностями (NE + левый сосед / NE + правый сосед)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_context = [{'IS_PUNCT': False}, {'LEMMA': {'IN': instruments}}]\n",
    "right_context = [{'LEMMA': {'IN': instruments}}, {'IS_PUNCT': False}]\n",
    "\n",
    "context_matcher = Matcher(nlp.vocab)\n",
    "context_matcher.add('left_context', None, left_context)\n",
    "context_matcher.add('right_context', None, right_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b9958ffbcc40a597677ac7f1a29e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=231344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "355482"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = []\n",
    "\n",
    "for doc in tqdm(processed_corpus):\n",
    "    matches = context_matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        context.append(span.text)\n",
    "        \n",
    "len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the guitar', 8934),\n",
       " ('the strings', 6238),\n",
       " ('my guitar', 5708),\n",
       " ('these strings', 4944),\n",
       " ('a guitar', 3965),\n",
       " ('guitar and', 3635),\n",
       " ('your guitar', 3476),\n",
       " ('this guitar', 2939),\n",
       " ('strings are', 2818),\n",
       " ('acoustic guitar', 2559)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = Counter(context)\n",
    "contexts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ранжируйте n-граммы с помощью 3 коллокационных метрик (t-score, PMI и т.д.). Не забудьте про частотный фильтр / сглаживание. Выберите лучший результат (какая метрика ранжирует выше коллокации, подходящие для отчёта)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берём только те биграммы, которые мы выделили в отзывах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for c in context:\n",
    "    n = 0\n",
    "    words = c.lower().split()\n",
    "    for word in words:\n",
    "        if word in stops:\n",
    "            n += 1\n",
    "    if n == 0:\n",
    "        ngrams.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "bigram_finder = BigramCollocationFinder.from_documents(ngrams)\n",
    "bigram_finder.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('zenergy', 'chimes'), 11.76051638283185),\n",
       " (('hammered', 'dulcimer'), 11.760516382831849),\n",
       " (('chimes', 'sat'), 11.526051129194826),\n",
       " (('mountain', 'dulcimer'), 11.455412910585846),\n",
       " (('bongo', 'cajon'), 10.979156669307187),\n",
       " (('hammond', 'organ'), 10.16783284504664),\n",
       " (('pitch', 'pipes'), 10.114657840145977),\n",
       " (('pitch', 'pipe'), 10.001370553816864),\n",
       " (('analog', 'synthesizers'), 9.985582938466619),\n",
       " (('note', 'chimes'), 9.965336174720349),\n",
       " (('cow', 'bell'), 9.707269256919421),\n",
       " (('tin', 'whistle'), 9.686222600484538),\n",
       " (('french', 'horn'), 9.441408807006862),\n",
       " (('tin', 'whistles'), 9.402964378213763),\n",
       " (('foot', 'tambourine'), 9.303624205041343)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_finder_pmi = bigram_finder.score_ngrams(bigram_measures.pmi)\n",
    "bigram_finder_pmi[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### likelihood ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('strings', 'guitar'), 10444.070288719724),\n",
       " (('guitar', 'bass'), 4569.310104011272),\n",
       " (('acoustic', 'guitar'), 4365.147320890128),\n",
       " (('great', 'strings'), 4207.626859105092),\n",
       " (('12', 'string'), 3602.89323876078),\n",
       " (('e', 'string'), 3446.696792048923),\n",
       " (('string', 'strings'), 3340.165883991948),\n",
       " (('guitar', 'string'), 3075.379070791222),\n",
       " (('guitar', 'strap'), 3072.4768184643426),\n",
       " ((\"d'addario\", 'strings'), 3039.273111044713),\n",
       " (('electric', 'guitar'), 2985.426071593826),\n",
       " (('drum', 'machine'), 2981.495152853903),\n",
       " (('drum', 'kit'), 2390.2428881263527),\n",
       " (('g', 'string'), 2314.294717138254),\n",
       " (('drum', 'set'), 2295.4041980755655)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_finder_likelihood = bigram_finder.score_ngrams(bigram_measures.likelihood_ratio)\n",
    "bigram_finder_likelihood[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jaccard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('pitch', 'pipe'), 0.27734375),\n",
       " (('mountain', 'dulcimer'), 0.23958333333333334),\n",
       " (('zenergy', 'chimes'), 0.17708333333333334),\n",
       " (('chimes', 'sat'), 0.1717171717171717),\n",
       " (('bongo', 'cajon'), 0.13761467889908258),\n",
       " (('alto', 'sax'), 0.1358921161825726),\n",
       " (('tin', 'whistle'), 0.13183279742765272),\n",
       " (('hammered', 'dulcimer'), 0.12359550561797752),\n",
       " (('note', 'chimes'), 0.12318840579710146),\n",
       " (('wind', 'screen'), 0.12278481012658228),\n",
       " (('analog', 'synthesizers'), 0.11904761904761904),\n",
       " (('wind', 'noise'), 0.11902113459399333),\n",
       " (('grand', 'piano'), 0.09595100374276964),\n",
       " (('pitch', 'pipes'), 0.09523809523809523),\n",
       " (('tenor', 'sax'), 0.09230769230769231)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_finder_jaccard = bigram_finder.score_ngrams(bigram_measures.jaccard)\n",
    "bigram_finder_jaccard[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мне кажется, лучше всего справляется PMI: выделяется больше качественных сочетаний и есть информация о конкретных брендах, но jaccard score тоже показал неплохие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Сгруппируйте полученные коллокации по NE, выведите примеры для 5 товаров. Должны получиться примерно такие группы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(collocations, finder, word):\n",
    "    reviews = []\n",
    "    for value in finder:\n",
    "        if value[0][0] == word or value[0][1] == word:\n",
    "            reviews.append(value[0][0] + \" \" + value[0][1])\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word:  guitar\n",
      "surf guitar\n",
      "avid guitar\n",
      "guitar center\n",
      "guitar processor\n",
      "guitar accessory\n",
      "\n",
      "\n",
      "Word:  sax\n",
      "bari sax\n",
      "alto sax\n",
      "sax mouthpiece\n",
      "tenor sax\n",
      "soprano sax\n",
      "\n",
      "\n",
      "Word:  banjo\n",
      "bluegrass banjo\n",
      "5-string banjo\n",
      "6-string banjo\n",
      "resonator banjo\n",
      "back banjo\n",
      "\n",
      "\n",
      "Word:  violin\n",
      "4/4 violin\n",
      "violin bow\n",
      "student violin\n",
      "violin hanger\n",
      "violin bridge\n",
      "\n",
      "\n",
      "Word:  bass\n",
      "bass traps\n",
      "beatle bass\n",
      "bronco bass\n",
      "bass boost\n",
      "muddy bass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INSTRUMENTS = ['guitar', 'sax', 'banjo', 'violin', 'bass']\n",
    "\n",
    "for word in INSTRUMENTS:\n",
    "    print('\\nWord: ', word)\n",
    "    print(*get_top(contexts, bigram_finder_pmi, word)[:5], sep='\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Способ объединить синонимичные упоминания (например, \"Samsung Galaxy Watch\", \"watch\", \"smartwatch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно взять векторные представления названий из метаданных и кластеризовать их. Или можно попробовать решить проблему предобученных моделей с помощью дополнительного обучения на нужных нам текстах, получить новые эмбеддинги и посчитать векторное расстояние. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
